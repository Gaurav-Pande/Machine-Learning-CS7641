{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FFy6leD3ZmzS"
   },
   "source": [
    "# Fall 2019 CX4641/CS7641 Homework 1\n",
    "\n",
    "## Instructor: Dr. Mahdi Roozbahani\n",
    "\n",
    "## Deadline: Sep 12, Thursday, 11:59 pm\n",
    "\n",
    "* No unapproved extension of the deadline is allowed. Late submission will lead to 0 credit. \n",
    "\n",
    "* Discussion is encouraged, but each student must write his own answers and explicitly mention any collaborators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C2Dz3TFIZmzT"
   },
   "source": [
    "## Instructions for the assignment\n",
    "\n",
    "In this assignment, we only have writing questions: you are asked to answer them in the markdown cells.\n",
    "\n",
    "- Graduate students are required to complete all the questions including **bouns parts**. Undergraduate students are welcome to try bouns questions and we will add them on your final grade.\n",
    "\n",
    "- To switch between cell for code and for markdown, see the menu -> Cell -> Cell Type\n",
    "    \n",
    "- You could directly type the Latex equations in the markdown cell.\n",
    "\n",
    "- Typing with Latex is highly recommended. An image scan copy of handwritten also works. If you hand write, try to be clear as much as possible. No credit may be given to unreadable handwriting.\n",
    "    \n",
    "- If you want to add any picture to your answer, you could use this syntax $\"<img src=\"\" style=\"width: 300px;\"/>\"$ to include them within your ipython notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vurwpE07ZmzU"
   },
   "source": [
    "## 1 Linear Algebra (25pts + 8pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6pSyvDOZmzU"
   },
   "source": [
    "### 1.1 Determinant and Inverse of Matrix [11pts]\n",
    "Given a matrix M:\n",
    "\n",
    "$$M = \\begin{bmatrix} \n",
    "  5 & 0 & 1 \\\\ \n",
    "  6 & 1 & 2 \\\\\n",
    "  0 & 4 & 3\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Calculate the determinant of M. [5pts]\n",
    "(Calculation process required)\n",
    "\n",
    "- Does the inverse of M exist? If so, calculate $M^{-1}$. [6pts]\n",
    "(Calculation process required)\n",
    "\n",
    "  (**Hint:** please double check your answer and make sure $M M^{-1} = I$)\n",
    "  \n",
    "### 1.2 Characteristic Equation [8pts] (BONUS)\n",
    "Consider the eigenvalue problem: \n",
    "  $$Ax =\\lambda x, x \\neq 0$$\n",
    "where $x$ is a non-zero eigenvector and $\\lambda$ is eigenvalue of $A$. Prove that the determinant $|A-\\lambda I|= 0$.\n",
    "\n",
    "(**Hint**: If a matrix is not full-rank (has linearly dependent columns), it is singular and non-invertible)\n",
    "\n",
    "\n",
    "### 1.3 Eigenvalue [7pts]\n",
    "Following 1.2, given a matrix $A$:\n",
    "   $$A = \n",
    "   \\begin{bmatrix} \n",
    "    1 & r \\\\ \n",
    "    r & 1 \n",
    "    \\end{bmatrix}$$ \n",
    "    \n",
    "Calculate all the eigenvalues of $A$. (Calculation process required. Your answer should be expressed as a function of $r$.)\n",
    "\n",
    "### 1.4 Eigenvector [7pts]\n",
    "Following 1.3, given that the $l_2$ norm of each eigenvector is 1, what are the eigenvectors of matrix $A$? For example, if an eigenvector is \n",
    "    ${v}=\\begin{bmatrix} \n",
    "    x1 \\\\ \n",
    "    x2 \n",
    "    \\end{bmatrix}$, then $||v||_2 = \\sqrt{x_1^2 + x_2^2} = 1$ (Calculation process required.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7D5eQGGiZmzV"
   },
   "source": [
    "## 2 Expectation, Co-variance and Independence [25pts + 5pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMqPtRogZmzV"
   },
   "source": [
    "Suppose $X, Y$ and $Z$ are three different random variables.\n",
    "Let $X$ obeys Bernouli Distribution. The probability disbribution function is\n",
    "    $$p(x)=\\left\\{\n",
    "    \\begin{array}{c l}\t\n",
    "         0.5 & x = c\\\\\n",
    "         0.5 & x = -c.\n",
    "    \\end{array}\\right.$$\n",
    "    $c$ is a constant here.\n",
    "Let $Y$ obeys the standard Normal (Gaussian) distribution, which can be written as $Y \\sim N(0,1)$. $X$ and $Y$ are independent. Meanwhile, let $Z = XY$.\n",
    "\n",
    "- What is the Expectation and Variance of $X$? (in terms of $c$) [4pts]\n",
    "- Show that when $c=1$, $Z$ is a standard Normal (Gaussian) distribution, which means $Z \\sim N(0,1)$. [9pts]\n",
    "- How should we choose $c$ such that Y and Z are uncorrelated (which means $Cov(Y,Z) = 0$)? [9pts]\n",
    "- Are Y and Z independent? (Just clarify) [3pts]\n",
    "- Show your conclusion for the above question with an example. **(Bouns)** [5pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHsbeDGNZmzX"
   },
   "source": [
    "## 3 Maximum Likelihood [25pts + 10pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QSEe9QB9ZmzY"
   },
   "source": [
    "### 3.1 Discrete Example [15pts]\n",
    "Suppose you are playing two unfair coins. The probability of tossing a head is $2 \\theta$ for coin 1, and $\\theta$ for coin 2. You toss each coin for several times, and you get the following results:\n",
    "\n",
    "| Coin No. | Result    |\n",
    "|------|------|\n",
    "|   1  | head |\n",
    "|   2  | head |\n",
    "|   1  | tail |\n",
    "|   2  | tail |\n",
    "|   1  | head |\n",
    "|   2  | tail |\n",
    "\n",
    "- What is the probability of tossing a tail for coin 1 ($p_{t1}$) and tossing a tail for coin 2 ($p_{t2}$) [3pts]? \n",
    "\n",
    "- What is the likelihood of the data given $\\theta$ [6pts]?\n",
    "\n",
    "- What is maximum likelihood estimation for $\\theta$ [6pts]?\n",
    "\n",
    "### 3.2 Continues Example [10pts] (BONUS)\n",
    "\n",
    "A uniform distribution in the range of $[a, b]$ is given by\n",
    "\n",
    "$$\n",
    "f(x)=\\left\\{\\begin{array}{ll}{\\frac{1}{b-a}} & {a \\leq x \\leq b} \\\\ {0} & {\\text { otherwise }}\\end{array}\\right.\n",
    "$$\n",
    "What is maximum likelihood estimation for $a$ and $b$?\n",
    "(You need to show the derivation of your answer.)\n",
    "\n",
    "( **Hint**: Think of two cases, where $x < max(x_1, x_2, ..., x_n)$ and $x \\ge max(x_1, x_2, ..., x_n).)$\n",
    "\n",
    "### 3.3 Maximum A Posteriori (MAP) [10pts]\n",
    "<img src = \"https://imgs.xkcd.com/comics/frequentists_vs_bayesians.png\" style=\"width:400px;height:600px\"/>\n",
    "\n",
    "(Reference: xkcd.com)\n",
    "\n",
    "Suppose there exists an unknown parameter $\\theta$ that describe whether the sun will explode tomorrow. $\\theta = 1$ means the sun will explode and $\\theta = 0$ if it won't. The likelihood function is:\n",
    "$$\n",
    "P(yes|\\theta)=\\left\\{\\begin{array}{ll}{1/36} & {\\theta = 0} \\\\ {35/36} & {\\theta = 1}\\end{array}\\right.\n",
    "$$\n",
    "- What is the maximum likelihood estimate of $\\theta$?[3pts]\n",
    "- Maximum A Posteriori (MAP) estimator aims to maximize the value of $\\theta$ in $p(\\theta|yes)$. What is the MAP estimate of $\\theta$ given that $P(\\theta=0)\\gg P(\\theta=1)$? Comment on the result.[7pts]\n",
    "\n",
    "( **Hint**: You can use Bayes Rule to get $p(\\theta|yes)$ from the likelihood! )\n",
    "\n",
    "To know more about MAP, refer to wiki page:\n",
    "https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ym8gpKMHZmzY"
   },
   "source": [
    "## 4 Information Theory [25pts + 7pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HSWti__DYx9"
   },
   "source": [
    "### 4.1 Marginal Distribution [4pts]\n",
    "Suppose the joint probability distribution of two binary random variables $X$ and $Y$ are given as follows.\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\\hline X | Y & {1} & {2} \\\\ \\hline 0 & {\\frac{1}{5}} & {\\frac{2}{5}} \\\\ \\hline 1 & {0} & \\frac{2}{5} \\\\ \\hline\\end{array}\n",
    "$$\n",
    "\n",
    "- Show the marginal distribution of $X$ and $Y$, respectively. [4pts]\n",
    "\n",
    "    \n",
    "### 4.2 Mutual Information and Entropy [21pts]\n",
    "Given a dataset as below.\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|c|c|}\\hline Day & Outlook & Temperature & Humidity & Wind & Play? \\\\ \\hline 1 & overcast & hot & normal & medium & yes \\\\ \\hline 2 & sunny & hot & high & weak & no \\\\ \\hline 3 & sunny & mild & normal & weak & yes \\\\ \\hline 4 & rain & cool & high & strong & no \\\\ \\hline 5 & overcast & cool & normal & strong & yes \\\\ \\hline 6 & rain & mild & normal & medium & no \\\\ \\hline 7 & sunny & mild & high & medium & yes\\\\ \\hline 8 & overcast & hot & normal & strong & no\\\\ \\hline 9 & rain & hot & high & weak & no\\\\ \\hline 10 & sunny & cool & normal & strong & yes\\\\\\hline\\end{array}\n",
    "$$\n",
    "\n",
    "We want to decide whether to play or not to play basketball on a certain day. Each input has four features ($x_1$, $x_2$, $x_3$, $x_4$): Outlook, Temperature, Humidity, Wind. The decision (play vs no-play) is represented as $Y$.\n",
    "\n",
    "- Find entropy $H(Y)$. [4pts]\n",
    "\n",
    "  \n",
    "  \n",
    "- Find conditional entropy $H(Y|x_1)$, $H(Y|x_4)$, respectively. [8pts]\n",
    "  \n",
    "  \n",
    "  \n",
    "- Find mutual information $I(x_1, Y)$ and $I(x_4, Y)$ and determine whether which one ($x_1$ or $x_4$) is more informative. [5pts]\n",
    "\n",
    "\n",
    "\n",
    "- Find joint entropy $H(Y, x_3)$. [4pts]\n",
    "  \n",
    "  \n",
    "### 4.3 Bonus Question [7pts]\n",
    "- Suppose $X$ and $Y$ are independent. Show that $H(X|Y) = H(X)$. [2pts]\n",
    "\n",
    "\n",
    "- Suppose $X$ and $Y$ are independent. Show that $H(X,Y) = H(X) + H(Y)$. [2pts]\n",
    "\n",
    "\n",
    "  \n",
    "- Prove that the mutual information is symmetric, i.e., $I(X, Y) = I(Y, X)$ and $x_i \\in X, y_i \\in Y$ [3pts]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1-template.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
